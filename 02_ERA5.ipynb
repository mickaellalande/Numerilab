{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERA5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To reload external files automatically (ex: utils)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import xarray as xr\n",
    "import dask\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar as cld\n",
    "import matplotlib.pyplot as plt\n",
    "import proplot as plot # New plot library (https://proplot.readthedocs.io/en/latest/)\n",
    "plot.rc['savefig.dpi'] = 300 # 1200 is too big! #https://proplot.readthedocs.io/en/latest/basics.html#Creating-figures\n",
    "from scipy import stats\n",
    "import xesmf as xe # For regridding (https://xesmf.readthedocs.io/en/latest/)\n",
    "\n",
    "# Import some extra functions from utils folder\n",
    "import sys\n",
    "sys.path.insert(1, 'utils') # to include the util directory\n",
    "import utils as u # my personal functions\n",
    "u.check_python_version()\n",
    "u.check_virtual_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download ERA5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Go to https://www.ecmwf.int/en/forecasts/datasets/reanalysis-datasets/era5\n",
    "2. Search `ERA5 monthly averaged data on single levels from 1979 to present`\n",
    "3. Download:\n",
    "    - Product type: Monthly averaged reanalysis\n",
    "    - Variable: 2m temperature\n",
    "    - Select all years (except 2021) / months / time\n",
    "    - Geographical area: Whole available region\n",
    "    - Format: NetCDF (experimental)\n",
    "4. Login/register to submit request (create an account if you don't have one)\n",
    "5. Go back down on the page and click on Submit Form\n",
    "6. Click on download, cancel, then right click on the download button and copy the link path, then paste it on the cell bellow besides the `wget` command\n",
    "\n",
    "Remark: It should be around 1Go\n",
    "\n",
    "Other Remark: using cdsapi...\n",
    "\n",
    "Copernicus also provides a python module `cdsapi` to handle files download. \n",
    "\n",
    "On the same screeen where you clicked `download`, clicking `Show API request`provides you the code copied in the next cell. *Here, it is commented out, because cdsapi does not work in binder. But it would work on a local installation. see https://cds.climate.copernicus.eu/api-how-to for details*\n",
    "\n",
    "This API ([Application Programming Interface](https://www.howtogeek.com/343877/what-is-an-api/)) is valid for the entire Copernicus climate and atmosphere data store, and particularly useful for systematic downloads\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import cdsapi\n",
    "\n",
    "c = cdsapi.Client()\n",
    "\n",
    "c.retrieve(\n",
    "    'reanalysis-era5-single-levels-monthly-means',\n",
    "    {\n",
    "        'product_type': 'monthly_averaged_reanalysis',\n",
    "        'variable': '2m_temperature',\n",
    "        'year': [\n",
    "            '1979', '1980', '1981',\n",
    "            '1982', '1983', '1984',\n",
    "            '1985', '1986', '1987',\n",
    "            '1988', '1989', '1990',\n",
    "            '1991', '1992', '1993',\n",
    "            '1994', '1995', '1996',\n",
    "            '1997', '1998', '1999',\n",
    "            '2000', '2001', '2002',\n",
    "            '2003', '2004', '2005',\n",
    "            '2006', '2007', '2008',\n",
    "            '2009', '2010', '2011',\n",
    "            '2012', '2013', '2014',\n",
    "            '2015', '2016', '2017',\n",
    "            '2018', '2019', '2020',\n",
    "            '2021',\n",
    "        ],\n",
    "        'month': [\n",
    "            '01', '02', '03',\n",
    "            '04', '05', '06',\n",
    "            '07', '08', '09',\n",
    "            '10', '11', '12',\n",
    "        ],\n",
    "        'time': '00:00',\n",
    "        'format': 'netcdf',\n",
    "    },\n",
    "    'download.nc')\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://download-0008.copernicus-climate.eu/cache-compute-0008/cache/data6/adaptor.mars.internal-1642500706.3691368-19649-5-5a435782-6700-4aa6-991b-f43bad55b9eb.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Rename the downloaded file to `ERA5.nc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read ERA5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('ERA5.nc')\n",
    "ds # ds as dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to get the temperature in °C (uncomment this cell and run this once)\n",
    "# da = ds.t2m - 273.15\n",
    "# da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oups if you are on Binder the kernel as shut down! This is because we have a very limited available amount of RAM (2Go). So we are going to have to trick to make this computation... Hopefully `xarray` comes with `dask` that allows easy parallel computation. Here we are not going to use the parallelization, but we are going to take advantage of Dask for splitting our data into multiple chunks to reduce to RAM usage!\n",
    "\n",
    "See more: http://xarray.pydata.org/en/stable/user-guide/dask.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/14822210/6344670\n",
    "import math\n",
    "\n",
    "def convert_size(size_bytes):\n",
    "    if size_bytes == 0:\n",
    "        return \"0B\"\n",
    "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "    i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "    p = math.pow(1024, i)\n",
    "    s = round(size_bytes / p, 2)\n",
    "    return \"%s %s\" % (s, size_name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_size(ds.t2m.nbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make chunks\n",
    "http://xarray.pydata.org/en/stable/user-guide/dask.html#what-is-a-dask-array\n",
    "\n",
    "![](http://xarray.pydata.org/en/stable/_images/dask_array.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.chunk(chunks={\"longitude\": 360, \"latitude\": 360})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.t2m.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that our dataset have been splited into 12 chunks of about 250 MB what is better than the 2 Go full array! So let's try back to convert to °C!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = ds.t2m - 273.15\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the execution of the cell is almost instantaneous. Why is this?Because the advantage of `dask.array` is that it is not loaded into memory until explicitly requested with `.load()`, `.compute()` or `.values`. It only builds graphs to prepare the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.visualize(da)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute and plot climatology\n",
    "Using the examples in the notebook `01_xarray_get_started.ipynb` try to calculate the climatology and make a graph with a projection (directly with Cartopy or Proplot). \n",
    "\n",
    "Remember to check the size of your `dask.array` before loading it into memory (`clim.load()`), which will make it easier to produce the graph (otherwise it will redo the calculation every time you make a graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim = da.mean('time')\n",
    "clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim.plot(robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Try to make a figure with a geographical projection of your choice using proplot (or directly matplotlib/cartopy). See back `01_xarray_get_started.ipynb` to help you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "Example of a solution with proplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "cmap='RdBu_r'\n",
    "levels=plot.arange(-30,30,5)\n",
    "extend='both'\n",
    "\n",
    "fig, axs = plot.subplots(nrows=1, ncols=1, proj='cyl', axwidth=5)\n",
    "\n",
    "axs[0].contourf(\n",
    "    clim, colorbar='r', cmap=cmap, levels=levels, extend=extend, \n",
    "    colorbar_kw={'label': 'Near-surface air temperature [°C]'}\n",
    ")\n",
    "\n",
    "axs.format(\n",
    "    labels=True, coast=True, borders=True,\n",
    "    suptitle='ERA5 near-surface air temperature climatology (1979-2020)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal and regional plots\n",
    "### Exercise\n",
    "Try to make seasonal climatology plots focused on the country you come from.\n",
    "\n",
    "Since the longitude data goes from 0 to 360, it is a bit more complicated if your region is around longitude 0. Two solutions, either you use the `.roll()` function to shift your whole dataset, or you use a mask with `.where()` (this last solution seems to me the easiest). You can also use the option `globe=True` in your `contourf()` with proplot to fill the 0 longitude.\n",
    "\n",
    "Also note that the latitudes are in descending order. So you have to reverse the values in the `.slice()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "Example over France\n",
    "\n",
    "#### Select zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "cmap='RdBu_r'\n",
    "levels=plot.arange(-4,20,2)\n",
    "extend='both'\n",
    "latmin=38 ; latmax=56 ; lonmin=-10 ; lonmax=15\n",
    "\n",
    "fig, axs = plot.subplots(nrows=1, ncols=1, proj='cyl', axwidth=4)\n",
    "\n",
    "axs[0].contourf(\n",
    "    clim.sel(latitude=slice(latmax,latmin)).where( (clim.longitude > 360+lonmin) | (clim.longitude < lonmax)), \n",
    "    colorbar='r', cmap=cmap, levels=levels, extend=extend, globe=True, \n",
    "    norm='div', # norm=plot.Norm('diverging', fair=False),\n",
    "    colorbar_kw={'label': 'Near-surface air temperature [°C]'}\n",
    ")\n",
    "\n",
    "axs.format(\n",
    "    labels=True, coast=True, borders=True, reso='med',\n",
    "    latlim=(latmin, latmax), lonlim=(lonmin, lonmax),\n",
    "    suptitle='France annual climatology ERA5 (1979-2020)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute seasonal climatologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "clim_seas = da.sel(latitude=slice(latmax,latmin)).where( (clim.longitude > 360+lonmin) | (clim.longitude < lonmax)) \\\n",
    "                .groupby('time.season').mean('time').load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot seasonal climatologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "cmap='RdBu_r'\n",
    "levels=plot.arange(-15,25,2)\n",
    "extend='both'\n",
    "\n",
    "fig, axs = plot.subplots(nrows=2, ncols=2, proj='cyl')\n",
    "\n",
    "seasons = ['DJF', 'MAM', 'JJA', 'SON']\n",
    "for i, ax in enumerate(axs):\n",
    "    m = ax.contourf(\n",
    "        clim_seas.sel(season=seasons[i]), cmap=cmap, levels=levels, extend=extend, globe=True, \n",
    "        norm=plot.Norm('diverging', fair=False)\n",
    "    )\n",
    "    ax.format(title=seasons[i])\n",
    "\n",
    "axs.format(\n",
    "    labels=True, coast=True, abc=True, reso='med',\n",
    "    latlim=(latmin, latmax), lonlim=(lonmin, lonmax),\n",
    "    suptitle='France seasonal climatologies ERA5 (1979-2020)'\n",
    ")\n",
    "\n",
    "fig.colorbar(m, label='Near-Surface Air Temperature [°C]')\n",
    "fig.save('img/france_seasonal_clim_t2m.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Share your plots!\n",
    "\n",
    "Go to the following link and upload your figure for your country!\n",
    "\n",
    "https://app.mural.co/t/variabiliteclimatique4363/m/variabiliteclimatique4363/1638958705203/74c3a90eb11e8e6898545872d80b8a41f0cd90ff?sender=ufcbfba826e94d93c633c7410"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute trends\n",
    "\n",
    "### Exercise: Make yearly mean\n",
    "\n",
    "Start by resampling the data to annual frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_year = ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "da_year = da.resample(time='Y').mean('time')\n",
    "da_year.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Spatially averaged time series\n",
    "Make spatial average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Spatially averaged time series (I use a function in the utils folder, same as seen in the tutorial)\n",
    "ts = u.spatial_average(da_year)\n",
    "ts.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make linear regression\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make linear regression\n",
    "reg = stats.linregress(ts['time.year'], ts)\n",
    "reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot.subplots(axwidth=5, aspect=2)\n",
    "\n",
    "x = ts['time.year']\n",
    "\n",
    "# Plot time serie\n",
    "axs[0].plot(x, ts)\n",
    "\n",
    "# Plot regression\n",
    "y = reg.slope*x + reg.intercept\n",
    "axs[0].plot(x, y, color='k', linewidth=1, linestyle='--')\n",
    "\n",
    "# Show regression\n",
    "axs[0].format(\n",
    "    ultitle='{:.2f} °C/dec (p-value: {:.2f})'.format(reg.slope*10, reg.pvalue)\n",
    ")\n",
    "\n",
    "axs.format(\n",
    "    xlabel='year',\n",
    "    ylabel='Near-Surface Air Temperature [°C]',\n",
    "    suptitle='ERA5 global temperature time serie'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial trends\n",
    "It would be very long to make a loop on each lat/lon, so we can vectorize the calculation with `apply_ufunc` of xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend(x, y, dim):\n",
    "    return xr.apply_ufunc(\n",
    "        stats.linregress, x, y,\n",
    "        input_core_dims=[[dim], [dim]],\n",
    "        output_core_dims=[[], [], [], [], []],\n",
    "        vectorize=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for arr_name, arr in zip(\n",
    "    ['slope', 'intercept', 'rvalue', 'pvalue', 'stderr'], \n",
    "    trend(da_year['time.year'], da_year, 'time')\n",
    "):\n",
    "    da_year[arr_name] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot.subplots(proj='cyl', axwidth=6)\n",
    "\n",
    "cmap='ColdHot'\n",
    "levels=plot.arange(-1,1,0.1)\n",
    "extend='both'\n",
    "\n",
    "m = axs[0].contourf(da_year.slope*10, cmap=cmap, levels=levels, extend=extend)\n",
    "axs[0].contourf(da_year.pvalue.where(da_year.pvalue>0.05), hatches=['////'], alpha=0)\n",
    "\n",
    "fig.colorbar(m, label='Near-Surface Air Temperature trends [°C/dec]', formatter=('simple', 3))\n",
    "\n",
    "# Format\n",
    "axs.format(\n",
    "    labels=True, coast=True,\n",
    "    suptitle='ERA5 Near-Surface Air Temperature annual trends (1979-2020)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Show Arctic Amplification\n",
    "Try to show Arctic Amplification with time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ts_arctic = u.spatial_average(da_year.sel(latitude=slice(90,60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plot.subplots(axwidth=5, aspect=2)\n",
    "\n",
    "x = ts['time.year']\n",
    "\n",
    "ts_list = [ts, ts_arctic]\n",
    "labels = ['Global', 'Arctic (>60°N)']\n",
    "\n",
    "for i, t in enumerate(ts_list):\n",
    "    # Compute clim on reference period to make anomalies\n",
    "    clim = t.sel(time=slice('1979', '2000')).mean()\n",
    "    \n",
    "    # Plot time serie\n",
    "    axs[0].plot(x, t-clim, color='C'+str(i), label=labels[i])\n",
    "\n",
    "    # Plot regression\n",
    "    reg = stats.linregress(t['time.year'], t-clim)\n",
    "    y = reg.slope*x + reg.intercept\n",
    "    axs[0].plot(x, y, color='C'+str(i), linewidth=1, linestyle='--', label='{:.2f} °C/dec ({:.2f})'.format(reg.slope*10, reg.pvalue))\n",
    "\n",
    "    \n",
    "axs[0].legend(ncol=2)\n",
    "\n",
    "# Add 0 line\n",
    "axs[0].hlines(0, x.min(), x.max(), linewidth=0.5, alpha=0.5)\n",
    "\n",
    "axs.format(\n",
    "    xlabel='year',\n",
    "    ylabel='Temperature anomalies [°C]',\n",
    "    suptitle='ERA5 global temperature anomalies (with respect to 1979-2000)',\n",
    "    xlim=(x.min(), x.max())\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
